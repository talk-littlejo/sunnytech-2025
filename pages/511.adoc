= 511 clusters
:imagesdir: assets/default/images
image::mi-511.png[]
//mi-dead-reckoning
[NOTE.speaker]
====
maintenant il reste un probl√®me pour aller au del√† de 256 clusters : aws
====

== Comment se d√©tacher de la limite AWS ?

[NOTE.speaker]
====
Comment aller au dela de cette limite.
====

== 2 comptes

[NOTE.speaker]
====
Ma premi√®re id√©e √©tait de d√©ployer sur 2 comptes AWS diff√©rents.
====

== !

image::511-2-accounts.svg[width=90%]

[NOTE.speaker]
====
Nous dupliquons l'infra sur les deux comptes et nous les relions avec un VPC peering :

* 256 clusters sur l'un
* 255 clusters sur l'autre

Cette solution m'a refroidi avec les soucis de d√©ploiement que j'avais eu avec le d√©ploiement de 256 clusters sur un seul compte.
====

== 7 comptes

[NOTE.speaker]
====
J'ai ensuite pens√© √† le faire sur 7 comptes AWS diff√©rents :

* 511 / 7 = 73 clusters par comptes
====

== !

image::511-7-accounts.svg[width=55%]

[NOTE.speaker]
====
De la m√™me mani√®re que pour 2 comptes, on va dupliquer l'infra sur les 7 comptes et on va les relier par une transit gateway.

J'√©tais pas totalement satisfait de cette solution car il faut cr√©er 7 comptes et il faudra penser √† les supprimer et j'ai trouv√© la derni√®re option √©tait plus sympa.
====

== 7 r√©gions
image::aws-map.png[]
[NOTE.speaker]
====
Nous allons cr√©er un cluster mesh sur 7 r√©gions AWS.
====

== !

image::511-7-regions.svg[width=55%]
[NOTE.speaker]
====
A priori l'architecture est similaire : on duplique l'architecture sur les diff√©rentes r√©gions. Mais il faut cr√©er une tgw par r√©gion et les connecter avec des tgw attachment.
====

== !

image::511-7-regions-deployment.svg[width=80%]

[NOTE.speaker]
====
On a maintenant choisi l'architecture. Mais comment d√©ployer cela ?

Cr√©er un serveur de d√©ploiement par r√©gion dont un serveur d√©di√© √† la connectivit√© : transit gateway et cilium cluster mesh
====

== üí∞ Pricing üí∞
[NOTE.speaker]
====
Un dernier d√©tail : combien √ßa coute tout √ßa ?
====

== !

[cols="1,1,1,1", options="header"]
|===
| Ressource | horaire | Quantit√© | 4h

| Cluster EKS | 0,10 $ | 511 | 204,40 $
| t4g.medium  | 0,0336 $ | 511 | 68,77 $
| c5a.2xlarge  | 0,3080 $ | 6 | 7,39 $
| c5a.16xlarge  | 2,464 $ | 1 | 9,86 $

|===

[NOTE.speaker]
====
Au niveau des ressources compute, on a ...
Les prix d√©pendent de la r√©gion o√π l'on d√©ploie. Donc c'est probablement un peu plus
====

== !

[cols="1,1,1,1", options="header"]
|===
| Ressource | horaire | Quantit√© | 4h

| NAT Gw | 0,045 $ | 7 | 1,26 $
| Transit Gw  | 0,10 $ | 7 | 2,80 $
| Transit Gw Attachment  | 0,50 $ | 13 | 26,00 $
| Total | | | 320,48 $
|===

[NOTE.speaker]
====
Au niveau des ressources r√©seaux, on a ...

Ce qui nous fait un total de 320 $
====

== Co√ªt üïµÔ∏è

[cols="1,1,1,1", options="header"]
|===
| Ressource | Gb | Quantit√© | Estimation

| NAT Gw | 0,045 $ | 511 | 22,995 $
| Transit Gw  | 0,05 $ | 7 | 0,35 $
|===
[NOTE.speaker]
====
On n'oublie pas les frais de transfert. Par exemple ce qui co√ªte le plus cher l√† c'est le t√©l√©chargement des images des containers avec une Nat GW.
====

== tests de 2 clusters par r√©gion

[NOTE.speaker]
====
Avant de d√©ployer 511 clusters, j'ai commenc√© √† d√©ployer 2 clusters par r√©gion pour v√©rifier la connectivit√© intra r√©gion.

Tout s'est bien pass√© : les tests √©galement.
====

== Les premiers d√©ploiements sur 511 clusters ü§û

image::511-terminal.png[width=70%]

[NOTE.speaker]
====
Je peux donc y aller avec confiance sur les 511 clusters !
====

== Les premiers d√©ploiement sur 511 clusters üò©
image::511-excel.png[width=70%]
[NOTE.speaker]
====
Les premiers d√©ploiements sont des √©checs :

* Probl√®mes de cidr

Quelques points d'inqui√©tudes :

* Le d√©ploiement des clusters EKS entre chaque r√©gion est tr√®s variable : de 15 minutes √† 45 minutes.
* Erreur d√©ploiement similaire √† ceux que j'ai eu pour 128 et 256 clusters
====

== Dernier test

[NOTE.speaker]
====
Tout s'est bien pass√© pour le dernier test...

Sauf sur une r√©gion o√π un cluster n'est pas bien d√©ploy√©.

J'ai quand m√™me test√© sur les 6 autres r√©gions :

6x73 = 438 clusters √ßa aurait √©t√© d√©j√† pas mal.

La cr√©ation des connexions a pris 1 h : le fait de cr√©er les clusters sur diff√©rentes r√©gions ralenti nous fait perdre √©norm√©ment

Malheureusement au moment des tests, il y avait des clusters qui n'√©taient pas bien connect√©s.

Cette derni√®re op√©ration a co√ªt√© 156 $.
====
