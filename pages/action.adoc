= PrÃ©sentation du terrain d'action
:imagesdir: assets/default/images
image::mi-action.png[]
//mi-4
[NOTE.speaker]
====
Maintenant que notre environnement d'entraÃ®nement est en place, Il est temps maintenant de **passer Ã  lâ€™action**.
====

== Choix stratÃ©gique : AWS EKS

[NOTE.speaker]
====
ğŸ§­ Premier choix dÃ©cisif : **le terrain dâ€™opÃ©ration**.  
Nous avons besoin dâ€™une plateforme capable dâ€™encaisser 511 clusters sans flancher.

ğŸ¯ Cible retenue : **AWS EKS**

* âœ… maÃ®trise d'AWS et d'EKS
* ğŸ›¡ï¸ Confiance pour supporter 511 clusters
====

== Limites imposÃ©es par AWS

image::service-quota.png[]

[NOTE.speaker]
====
ğŸ’¥ Premier obstacle : les limites AWS

AWS bloque Ã  **100 clusters max**.

ğŸ© Tentative : nÃ©gociation.

â³ AprÃ¨s plusieurs semaines : refus pour 511.

âœ… RÃ©sultat obtenu : **256 clusters** autorisÃ©s.

Par contre pour rÃ©ussir Ã  crÃ©er 256 clusters rapidement, il va falloir faire quelques entorses aux bonnes pratiques AWSâ€¦
====

== Bonnes pratiques vs RÃ©alitÃ© opÃ©rationnelle

image::nodepool.apng[width=60%]

[NOTE.speaker]
====
Prenons un exemple.

ğŸ“˜ Selon les bonnes pratiques AWS, pour crÃ©er des workers EKS, il faut : crÃ©er des Node Pools, qui crÃ©ent des ASG  qui crÃ©ent des EC2.

ğŸš¨ Sauf que tout Ã§a prend un **temps fou**.

ğŸ¯ On va crÃ©er **directement des EC2**, sans passer par les surcouches d'AWS.

ğŸ‘‰ Regardons maintenant lâ€™architecture AWS retenue pour concilier rapiditÃ© et bonnes pratiques.
====

== Architecture retenue

image::aws-archi.svg[width=50%]

[NOTE.speaker]
====
On a un compte AWS, un VPC, un rÃ©seau privÃ©. Ã€ l'intÃ©rieur il contient 4 sous-rÃ©seaux 2 publics 2 privÃ©s.

Dans les sous-rÃ©seaux public il y a une NAT Gateway pour pouvoir tÃ©lÃ©charger les images des containers depuis les sous-rÃ©seaux privÃ©s.

Dans les rÃ©seaux privÃ©, il y a les clusters EKS avec une seule EC2 et un control plane.

Avant de faire des tests en grandeur nature, il est temps de voir comment on a attaquÃ© le problÃ¨me de la crÃ©ation des connexions Cilium pour gagner du temps de dÃ©ploiement.
====

== ParallÃ©lisation des connexions

image::connection-answer.apng[width=45%]
[NOTE.speaker]
====
Je vous prÃ©sente la premiÃ¨re tentative pour parallÃ©liser les connexions entre clusters.

Contrainte : un cluster ne peut participer quâ€™Ã  une seule connexion Ã  la fois.

Avec cet algorithme, pour 6 clusters Kubernetes, on passe de 15 Ã©tapes (toutes les connexions une par une) Ã  seulement 5 Ã©tapes â€” une par round.

Cet algorithme sâ€™appelle un **tournoi toutes rondes**. Câ€™est le mÃªme principe que dans une poule de foot, oÃ¹ chaque Ã©quipe affronte toutes les autres, une fois par journÃ©e.

On va maintenant tester cette parallÃ©lisation sur 32 clusters Kubernetes.
====

== 32 clusters

image::mission_failed.apng[width=50%]

[NOTE.speaker]
====
Le test de 32 clusters a Ã©chouÃ©

âŒ Mur technique dÃ©tectÃ© :

* ğŸ“¦ Trop dâ€™objets Pulumi
* n x n-1 / 2 objets pour crÃ©er les connexion => environ 500 objets Pulumi dÃ©diÃ© aux connexions
* explosion de la RAM ğŸ’¥

Je vais rÃ©duire Ã  16 clusters
====

== 16 clusters

image::16-clusters.apng[width=50%]

[NOTE.speaker]
====
ğŸ“‰ RÃ©sultat :

* âœ… 16 clusters connectÃ©s
* â±ï¸ 45 minutesâ€¦
* ğŸš« Bien trop long pour 511 clusters

ğŸ” Connexions entre clusters â†’ explosion du CPU

* 1 connexion â‰ˆ 1 CPU utilisÃ©
* 128 connexions = 128 CPUs ? ğŸ˜…


* Il faut une autre stratÃ©gie de connexion pour aller plus loin.
====
